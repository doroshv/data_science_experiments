{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc6acb7-8f74-451b-9fe3-a27135301cb2",
   "metadata": {},
   "source": [
    "# Crowdflower Search Results Relevance\n",
    "\n",
    "Educational take on one of the more popular past [kaggle challenges](https://www.kaggle.com/c/crowdflower-search-relevance/data) from 2015 with LLMs. Note that this is not an appropriate approach for the problem and is done only for fun! See the second notebook (crowdflower_classical) for a more sensible approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c7b91219-6cf7-4eeb-bad3-aee4df7ae02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id  median_relevance  relevance_variance\n",
      "count  10158.000000      10158.000000        10158.000000\n",
      "mean   16353.103071          3.309805            0.377863\n",
      "std     9447.106683          0.980666            0.389707\n",
      "min        1.000000          1.000000            0.000000\n",
      "25%     8078.750000          3.000000            0.000000\n",
      "50%    16349.500000          4.000000            0.471000\n",
      "75%    24570.750000          4.000000            0.471000\n",
      "max    32668.000000          4.000000            1.470000\n",
      "id                        0\n",
      "query                     0\n",
      "product_title             0\n",
      "product_description    2444\n",
      "median_relevance          0\n",
      "relevance_variance        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9904</th>\n",
       "      <td>31830</td>\n",
       "      <td>bike lock</td>\n",
       "      <td>Masterlock Cable And Key 5-ft.</td>\n",
       "      <td>Secure your bicycle on a bike rack with this c...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>14543</td>\n",
       "      <td>full tang knife</td>\n",
       "      <td>GW1538BONE Bone Handle Gut Hook Full Tang Skin...</td>\n",
       "      <td>FeaturesFull tang, bone handle, gut hook skinn...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>4809</td>\n",
       "      <td>wall clocks</td>\n",
       "      <td>New Fashion Large Number Wall Clock Diy 3D Mir...</td>\n",
       "      <td>eBay item number:361076423179\\n\\n\\n\\tSeller as...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>20846</td>\n",
       "      <td>leather mens briefcase</td>\n",
       "      <td>McKlein Ladies Leather Briefcase - Red</td>\n",
       "      <td>This ladies' briefcase by McKlein is a fashion...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>20365</td>\n",
       "      <td>white jeans</td>\n",
       "      <td>Bluberry Women's Slim Cut Colored Denim Jeans</td>\n",
       "      <td>ITEM#: 16728155\\nThe fashionista's favorite, t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>16619</td>\n",
       "      <td>an extremely goofy movie</td>\n",
       "      <td>An Extremely Goofy Movie (VHS, 2000) CLAM SHELL</td>\n",
       "      <td>eBay item number:291435965025\\n\\n\\n\\tSeller as...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>20164</td>\n",
       "      <td>car window sticker</td>\n",
       "      <td>US Air Force Logo Bumper Sticker</td>\n",
       "      <td>United States Air Force Logo Bumper Sticker: S...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>16610</td>\n",
       "      <td>wii</td>\n",
       "      <td>BD&amp;A Wii Fit Neoprene Bag (Wii)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>19172</td>\n",
       "      <td>playstation 4</td>\n",
       "      <td>PS4 - Knack</td>\n",
       "      <td>He's mean. He's mighty. He's powerful. He's......</td>\n",
       "      <td>2</td>\n",
       "      <td>1.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8494</th>\n",
       "      <td>27355</td>\n",
       "      <td>face cream</td>\n",
       "      <td>FUJI BEE VENOM CREAM New, Anti-aging, Face, Sk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                     query  \\\n",
       "9904  31830                 bike lock   \n",
       "4505  14543           full tang knife   \n",
       "1487   4809               wall clocks   \n",
       "6468  20846    leather mens briefcase   \n",
       "6308  20365               white jeans   \n",
       "5154  16619  an extremely goofy movie   \n",
       "6247  20164        car window sticker   \n",
       "5150  16610                       wii   \n",
       "5956  19172             playstation 4   \n",
       "8494  27355                face cream   \n",
       "\n",
       "                                          product_title  \\\n",
       "9904                     Masterlock Cable And Key 5-ft.   \n",
       "4505  GW1538BONE Bone Handle Gut Hook Full Tang Skin...   \n",
       "1487  New Fashion Large Number Wall Clock Diy 3D Mir...   \n",
       "6468             McKlein Ladies Leather Briefcase - Red   \n",
       "6308      Bluberry Women's Slim Cut Colored Denim Jeans   \n",
       "5154    An Extremely Goofy Movie (VHS, 2000) CLAM SHELL   \n",
       "6247                   US Air Force Logo Bumper Sticker   \n",
       "5150                    BD&A Wii Fit Neoprene Bag (Wii)   \n",
       "5956                                        PS4 - Knack   \n",
       "8494  FUJI BEE VENOM CREAM New, Anti-aging, Face, Sk...   \n",
       "\n",
       "                                    product_description  median_relevance  \\\n",
       "9904  Secure your bicycle on a bike rack with this c...                 3   \n",
       "4505  FeaturesFull tang, bone handle, gut hook skinn...                 4   \n",
       "1487  eBay item number:361076423179\\n\\n\\n\\tSeller as...                 2   \n",
       "6468  This ladies' briefcase by McKlein is a fashion...                 2   \n",
       "6308  ITEM#: 16728155\\nThe fashionista's favorite, t...                 4   \n",
       "5154  eBay item number:291435965025\\n\\n\\n\\tSeller as...                 4   \n",
       "6247  United States Air Force Logo Bumper Sticker: S...                 2   \n",
       "5150                                                NaN                 2   \n",
       "5956  He's mean. He's mighty. He's powerful. He's......                 2   \n",
       "8494                                                NaN                 3   \n",
       "\n",
       "      relevance_variance  \n",
       "9904               0.748  \n",
       "4505               0.000  \n",
       "1487               1.020  \n",
       "6468               0.471  \n",
       "6308               0.800  \n",
       "5154               0.000  \n",
       "6247               0.471  \n",
       "5150               0.943  \n",
       "5956               1.020  \n",
       "8494               0.471  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "print(df.describe())\n",
    "print(df.isna().sum())\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c6ab3-ff05-4c37-a946-a9e006230ef7",
   "metadata": {},
   "source": [
    "One can see that there are quite a few missing product descriptions, but otherwise the dataset is fine and product title is sufficient to rate relevance. So, as a first step, we can replace NaNs with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bd0f4638-fe31-4c9e-a99d-e355dea6ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['product_description'].isna(),'product_description'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31999b-8ed0-4d2c-b8fd-56fe78bcbfbe",
   "metadata": {},
   "source": [
    "Now we can proceed to set a benchmark using an LLM. The idea is to:\n",
    "- generate embeddings for query string to identify similar queries\n",
    "- use subset of the training set to define good examples for a few-shot promt for LLM asking to rate relevance of a given query using those examples\n",
    "- repeat process with a different set of examples several times and calculate median\n",
    "\n",
    "I use here *nomic-embed-text* (=overkill, but that's an LLM-based solution!) for embeddings and small versions of gemma/llamma as LLM (both via ollama) for speed/cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "cdc468fa-17c3-4d3b-be24-08dee91b5999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79befbcbbc524e33978cb5d2cea600a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ollama\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "df['query_embedding'] = df['query'].progress_apply(lambda x: ollama.embeddings(model='nomic-embed-text', prompt=x)['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40324ecc-74d2-4f79-a981-1e4f655c06ce",
   "metadata": {},
   "source": [
    "We can also create a separate columns containing concatenated query/response and same text plus answer for few shot prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e56295fa-9c47-4efa-bfaa-3fcb8d215fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "      <th>query_embedding</th>\n",
       "      <th>prompt_template</th>\n",
       "      <th>query_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>19663</td>\n",
       "      <td>electric griddle</td>\n",
       "      <td>Oster 16</td>\n",
       "      <td>With a 16\" x 10\" cooking surface and an adjust...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[-0.40113887190818787, 2.41182804107666, -4.00...</td>\n",
       "      <td>Query: electric griddle\\n Result: Oster 16 Wit...</td>\n",
       "      <td>Query: electric griddle\\n Result: Oster 16 Wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>4193</td>\n",
       "      <td>led monitor</td>\n",
       "      <td>Planar PXL2240MW 22 Edge LED LCD Touchscreen M...</td>\n",
       "      <td>The Planar PXL2240MW is a 22\" budget-friendly ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943</td>\n",
       "      <td>[-0.41080495715141296, 1.3763008117675781, -3....</td>\n",
       "      <td>Query: led monitor\\n Result: Planar PXL2240MW ...</td>\n",
       "      <td>Query: led monitor\\n Result: Planar PXL2240MW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>18170</td>\n",
       "      <td>gold dress</td>\n",
       "      <td>Gold SeriesÜ¢ Men's Big &amp; Tall Blue Wrinkle-F...</td>\n",
       "      <td>From the boardroom to an anniversary dinner, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471</td>\n",
       "      <td>[-0.18501344323158264, 1.2429983615875244, -3....</td>\n",
       "      <td>Query: gold dress\\n Result: Gold SeriesÜ¢ Men...</td>\n",
       "      <td>Query: gold dress\\n Result: Gold SeriesÜ¢ Men...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id             query  \\\n",
       "6104  19663  electric griddle   \n",
       "1298   4193       led monitor   \n",
       "5650  18170        gold dress   \n",
       "\n",
       "                                          product_title  \\\n",
       "6104                                           Oster 16   \n",
       "1298  Planar PXL2240MW 22 Edge LED LCD Touchscreen M...   \n",
       "5650  Gold SeriesÜ¢ Men's Big & Tall Blue Wrinkle-F...   \n",
       "\n",
       "                                    product_description  median_relevance  \\\n",
       "6104  With a 16\" x 10\" cooking surface and an adjust...                 4   \n",
       "1298  The Planar PXL2240MW is a 22\" budget-friendly ...                 4   \n",
       "5650  From the boardroom to an anniversary dinner, t...                 1   \n",
       "\n",
       "      relevance_variance                                    query_embedding  \\\n",
       "6104               0.000  [-0.40113887190818787, 2.41182804107666, -4.00...   \n",
       "1298               0.943  [-0.41080495715141296, 1.3763008117675781, -3....   \n",
       "5650               0.471  [-0.18501344323158264, 1.2429983615875244, -3....   \n",
       "\n",
       "                                        prompt_template  \\\n",
       "6104  Query: electric griddle\\n Result: Oster 16 Wit...   \n",
       "1298  Query: led monitor\\n Result: Planar PXL2240MW ...   \n",
       "5650  Query: gold dress\\n Result: Gold SeriesÜ¢ Men...   \n",
       "\n",
       "                                           query_result  \n",
       "6104  Query: electric griddle\\n Result: Oster 16 Wit...  \n",
       "1298  Query: led monitor\\n Result: Planar PXL2240MW ...  \n",
       "5650  Query: gold dress\\n Result: Gold SeriesÜ¢ Men...  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompt_template'] = \"Query: \" + df['query'] + '\\n Result: ' + df['product_title'] + ' ' + df['product_description'] + '\\n Relevance: '+ df['median_relevance'].astype(str)\n",
    "df['query_result'] = \"Query: \" + df['query'] + '\\n Result: ' + df['product_title'] + ' ' + df['product_description'] \n",
    "df.sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88c1ad-ae35-4df7-8704-853abfa88071",
   "metadata": {},
   "source": [
    "The next step is to extract relevant examples. Note that the queries are not unique, i.e. there are at least 8 samples of the same query (sometimes more), so feeding similar queries with different answers seems like a natural choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6a95557a-677d-4294-b704-999008ee90c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query\n",
       "wireless mouse             113\n",
       "rachel ray cookware         91\n",
       "memory foam pillow          90\n",
       "bike lock                   84\n",
       "16 gb memory card           64\n",
       "                          ... \n",
       "longboard pads              13\n",
       "silicone toe separators     12\n",
       "8 ounce mason jars          10\n",
       "polo bear sweater           10\n",
       "dollhouse bathtub            8\n",
       "Name: count, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['query'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a09e7-d709-4243-bb44-a9d2314de35d",
   "metadata": {},
   "source": [
    "Note that similar is not necessarily the same as it is not guaranteed that the test set will contain same queries as training set. Use embeddings and cosine similarity for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a7437bcd-9876-4a22-99a6-56154e856c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_n_closest_cosine(query_text, n=3):\n",
    "    # get target embedding\n",
    "    target_embedding = np.array(ollama.embeddings(model='nomic-embed-text', prompt=query_text)['embedding']).reshape(1, -1)\n",
    "    # exclude example if it is found in training set\n",
    "    df_mdf = df[(df['query_result']!=query_text) & (df['relevance_variance'] == 0) ] # use only clean examples for few shot!\n",
    "    # Calculate cosine similarities\n",
    "    similarities = cosine_similarity(np.stack(df_mdf['query_embedding'].values), target_embedding).flatten()\n",
    "    # Get indices of the top n+1 closest (excluding the target itself at index)\n",
    "    closest_indices = np.argsort(-similarities)[:n]\n",
    "    # Return the closest matches\n",
    "    return df_mdf.iloc[closest_indices]['prompt_template']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3caa447-6971-4d87-9aa8-6947c443788d",
   "metadata": {},
   "source": [
    "Now we can draft function for scoring. I use *n_examples* for few shot prompting and repeat procedure *n_rounds* with different examples, i.e. we need n_examples times n_rounds cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0c835120-0eba-428a-ac55-99bdafdcf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "prompt_intro = \"\"\"\n",
    "You are an expert search quality analyst with extensive experience in evaluating \n",
    "the relevance of search results. Your task is to assess the relevance of search query \n",
    "results on a scale from 1 to 4 and respond with a single number. The relevance scale is\n",
    "\n",
    "1 - Not relevant at all\n",
    "2 - Somewhat relevant, but missing key information or outdated\n",
    "3 - Mostly relevant, with minor issues or omissions\n",
    "4 - Highly relevant and directly answers the query\n",
    "\n",
    "You have a deep understanding of user intent and can accurately judge how well a search result matches the user's query. \n",
    "Please use the following examples as a guide to rate the relevance of the given search query and result:\\n\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_relevance_text(query_text, n_examples=3, n_rounds=5, model='llama3-chatqa'):\n",
    "    prompt_outro = f'Now, rate the relevance of the following search query result on a scale from 1 to 4 and respond with a single number. Be sure not to include any other text in your response and that the score you output is strictly between 1 and 4. If you do not know, just guess. The text to rate: {query_text}'\n",
    "    examples = get_n_closest_cosine(query_text, n_examples*n_rounds)\n",
    "    res = []\n",
    "    for r in range(n_rounds):\n",
    "        example_part = ''\n",
    "        for exn,ex in enumerate(examples[r*n_examples:(r+1)*n_examples]):\n",
    "            example_part+= f'Example {exn+1}\\n' + ex + '\\n'\n",
    "        prompt = prompt_intro + example_part + prompt_outro\n",
    "        response = ollama.chat(model=model, messages=[{'role': 'user','content': prompt,},])\n",
    "        try:\n",
    "            # print(response['message']['content'])\n",
    "            res.append(int(response['message']['content']))\n",
    "        except:\n",
    "            pass\n",
    "    # print(res)\n",
    "    try:\n",
    "        return int(mode(res).mode) # effectively majority vote\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba98226-e85d-4ad3-acc9-cc9c29ee667b",
   "metadata": {},
   "source": [
    "Let us test the results on a subset of training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a76325d4-0357-46fd-8c36-d01c3d9f979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8efd385b0cd45a197e5570c217ee034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_short = df.sample(n=100)\n",
    "# get_relevance_text(df_short['query_result'].iloc[0]) # to test the model output\n",
    "df_short['llm_rank'] = df_short['query_result'].progress_apply(get_relevance_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a8ea9f18-24ed-4907-bd93-60a01cf2fed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x347b8d300>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "plt.matshow(pd.crosstab(df_short['median_relevance'],df_short['llm_rank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "991930c7-f52b-4bd0-884b-43e301a5c2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean       3.580000\n",
       "std        0.741007\n",
       "min        1.000000\n",
       "25%        3.000000\n",
       "50%        4.000000\n",
       "75%        4.000000\n",
       "max        4.000000\n",
       "Name: llm_rank, dtype: float64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short['llm_rank'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea53e48-0406-48b3-aa15-70c8dd6faa03",
   "metadata": {},
   "source": [
    "And evaluate results according to competition metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "09627887-ed7a-4ddf-92be-cc67ca66c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic weighted kappa for subset is 0.4323342415985467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "qwk = cohen_kappa_score(df_short['median_relevance'], df_short['llm_rank'], weights='quadratic')\n",
    "print(f\"Quadratic weighted kappa for subset is {qwk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983f5c7-c229-408b-bf6d-52f0efd4eb14",
   "metadata": {},
   "source": [
    "Not really impressive (the winner had 0.72 or so, and 0.43 is not even in top 1000), and very wasteful! Accuracy can probably be improved with better prompting, more rounds or more complex models, but processing already takes quite a bit of compute (few seconds per row each on MBP M1 depending on number of rounds/examples). The message is thus that it's not always sensible to use LLMs even for NLP tasks.\n",
    "\n",
    "Note, however, that there is one major advantage of this approach (even if not in context of the particular competition). Basically, neither quality nor even availability of the training data matters that much for LLMs! In principle, results will not be much worse with generic prompt not tuned to specific use case, especially if more complex models and more attempts would be taken. That's a valid use case, but not really in line with spirit of the computation (and LLMs were not available in 2015), so I just write down how the application to the test would be but not run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "40012986-b0c5-4168-9439-bc50f6286e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('test.csv')\n",
    "# df_test.loc[df_test['product_description'].isna(),'product_description'] = ''\n",
    "# df_test['query_result'] = \"Query: \" + df_test['query'] + '\\n Result: ' + df_test['product_title'] + ' ' + df_test['product_description'] \n",
    "# df_test['llm_rank'] = df_test['query_result'].progress_apply(get_relevance_text)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6702c-7505-4308-b2f6-b30ff9346780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
